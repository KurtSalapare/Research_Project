Average Computation Time per URL per Model irrespective to prompts				Average Computation Time per URL per Model per Prompt									
URL	MODEL	AVG COMP TIME		URL	MODEL	PROMPT	AVG COMP TIME		URL	MODEL	PROMPT	SCORE	SCORE COUNT
https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	2.862749871		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2.435111571		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	88
https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	0.578556697		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3.647734194		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	13
https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	0.620176572		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2.505403848		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	9
https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	0.678069799		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.481538923		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	19
https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	1.581819545		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.568223821		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	123
https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	2.296352583		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.685907347		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	3
https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	0.624656772		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.518365883		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3	3
https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	0.628668189		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.708291074		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	88
https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	0.803101934		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.63387276		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	15
https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	1.689643377		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.628061307		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	15
https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	2.538636464		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.728804752		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	3	11
https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	0.708846464		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.677343339		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	32
https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	0.707290609		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1.47852145		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	68
https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	0.809007357		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1.71676908		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	29
https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	1.75792361		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1.550168107		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	106
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1.956205476		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	14
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2.779018555		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3	9
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2.153833717		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	89
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.503878283		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	11
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.655570417		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	19
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.714521617		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	3	10
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.56871989		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	58
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.615485534		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	52
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.701799141		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	19
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.796632931		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	127
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.804746238		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	2
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.807926634		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	79
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1.502896262		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	22
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1.703963645		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	23
				https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1.862070224		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	3	5
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1.8712154		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	77
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3.161861896		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	49
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2.582832096		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	3
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.502854017		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	49
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.779204457		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	77
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.844480917		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3	3
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.517533474		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	76
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.729522913		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	50
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.874815439		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	3	3
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0.691178626		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	5
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0.834002809		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	33
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0.901840635		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	91
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1.537198774		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	126
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1.811835774		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3	3
				https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1.924736283		https://hiddenlayer.com/innovation-hub/novel-universal-bypass-for-all-major-llms/	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	129
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	25
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	4
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	19
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	2
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	8
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	24
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	5
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	3
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	26
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	17
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	12
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	13
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	14
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	2
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	12
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	17
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	29
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	3
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	26
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	2
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	27
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	2
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	27
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	14
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	15
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	3
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	26
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	28
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	3	1
									https://www.cloudflare.com/learning/security/threats/owasp-top-10/	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	29
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	19
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	18
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	3
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	22
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	gemma:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	20
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	1	5
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	18
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	13
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	8
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	llama3:8b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	3	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	21
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	23
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	12
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mannix/llama3.1-8b-abliterated:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	9
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	1	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	21
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	2	22
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	1	2
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	mistral:latest	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	2	21
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	0	4
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	2	1
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Concise Prompt
Classify text for relevance to AI prompt engineering/adversarial strategies. Output JSON: {""usability_score"": int, ""reason"": ""string""}.
Scores:
1 - Not Useful: Irrelevant/random text.
2 - Potentially Useful: Discusses general concepts/strategies (not a direct prompt).
3 - An Example Prompt Itself: Direct, runnable AI prompt example.
Example Output: {""usability_score"": 1, ""reason"": ""...""}
"	3	18
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Few Shot Prompt
You are a helpful assistant. You are designed to classify text based on its relevance to AI security vulnerabilities and adversarial prompt strategies.
Your response MUST be a JSON object with two keys: ""usability_score"" (an integer: 1, 2, or 3) and ""reason"" (a string explaining the classification).

Here are the classification criteria:
1.  **usability_score: 1 (Not Useful for AI Security)**
    * The text is irrelevant, has no clear connection to AI security vulnerabilities, adversarial prompt attacks, or related defense strategies. It's just random text.
2.  **usability_score: 2 (Potentially Useful for AI Security Analysis)**
    * The text discusses general AI security concepts, vulnerabilities (e.g., prompt injection, data poisoning, model extraction, privacy leakage via inference), attack methodologies, or defense strategies.
    * It describes *how such attacks work* or *how to create/mitigate them*, but it is NOT a direct, runnable example of an attack prompt itself.
3.  **usability_score: 3 (Direct Adversarial Security Prompt Example)**
    * The text is a direct, runnable example of a prompt intended for an AI model that is designed to exploit, test, or reveal AI security vulnerabilities (e.g., attempting data exfiltration, unauthorized access, bypassing security filters, exploiting code execution vulnerabilities, or revealing sensitive training data/model architecture).

Example Output Format:
{""usability_score"": 1, ""reason"": ""The text is irrelevant.""}
{""usability_score"": 2, ""reason"": ""The text discusses general AI security concepts.""}
{""usability_score"": 3, ""reason"": ""The text is a direct example of an adversarial security prompt.""}
"	0	23
									https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems	qwen:7b	"Structured Prompt
### Persona/Role
You are a helpful assistant. Your core function is to analyze and classify provided text content.

### Objective
Classify the given text based on its relevance to AI prompt engineering and adversarial prompt strategies.

### Classification Criteria
Assign a ""usability_score"" (integer: 1, 2, or 3) and provide a concise ""reason"" (string) for the classification, strictly adhering to the following definitions:

1.  **usability_score: 1 (Not Useful)**
    * **Criterion:** The text is irrelevant to AI prompt engineering or adversarial prompt strategies. It contains random or unrelated content.

2.  **usability_score: 2 (Potentially Useful)**
    * **Criterion:** The text discusses general concepts, methodologies, or strategies related to AI adversarial prompt engineering.
    * **Distinction:** It *describes* how to approach or understand such concepts but is NOT a direct, runnable example of an actual prompt.

3.  **usability_score: 3 (An Example Prompt Itself)**
    * **Criterion:** The text is a direct, executable example of a prompt explicitly designed for an AI model. This includes clear instructions or structures that an AI would process as a direct instruction.

### Output Format
Your response MUST be a JSON object containing exactly two keys: ""usability_score"" and ""reason"".

**Example Outputs:**
* `{""usability_score"": 1, ""reason"": ""The text discusses general geography, not AI prompt strategies.""}`
* `{""usability_score"": 2, ""reason"": ""The text explains principles of prompt injection, but isn't a prompt.""}`
* `{""usability_score"": 3, ""reason"": ""The text provides a direct instruction set for an AI model.""}`
"	0	23
